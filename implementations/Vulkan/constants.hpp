#ifndef AGPU_VULKAN_CONSTANTS_HPP
#define AGPU_VULKAN_CONSTANTS_HPP

#include "common.hpp"
#include "include_vulkan.h"

namespace AgpuVulkan
{

inline VkShaderStageFlagBits mapShaderType(agpu_shader_type type)
{
    switch (type)
    {
    default:
    case AGPU_VERTEX_SHADER: return VK_SHADER_STAGE_VERTEX_BIT;
    case AGPU_FRAGMENT_SHADER: return VK_SHADER_STAGE_FRAGMENT_BIT;
    case AGPU_GEOMETRY_SHADER: return VK_SHADER_STAGE_GEOMETRY_BIT;
    case AGPU_COMPUTE_SHADER: return VK_SHADER_STAGE_COMPUTE_BIT;
    case AGPU_TESSELLATION_CONTROL_SHADER: return VK_SHADER_STAGE_TESSELLATION_CONTROL_BIT;
    case AGPU_TESSELLATION_EVALUATION_SHADER: return VK_SHADER_STAGE_TESSELLATION_EVALUATION_BIT;
    }
}

inline enum VkPrimitiveTopology mapTopology(agpu_primitive_topology topology)
{
    switch (topology)
    {
    default:
    case AGPU_POINTS: return VK_PRIMITIVE_TOPOLOGY_POINT_LIST;
    case AGPU_LINES: return VK_PRIMITIVE_TOPOLOGY_LINE_LIST;
    case AGPU_LINES_ADJACENCY: return VK_PRIMITIVE_TOPOLOGY_LINE_LIST_WITH_ADJACENCY;
    case AGPU_LINE_STRIP: return VK_PRIMITIVE_TOPOLOGY_LINE_STRIP;
    case AGPU_LINE_STRIP_ADJACENCY: return VK_PRIMITIVE_TOPOLOGY_LINE_STRIP_WITH_ADJACENCY;
    case AGPU_TRIANGLES:  return VK_PRIMITIVE_TOPOLOGY_TRIANGLE_LIST;
    case AGPU_TRIANGLES_ADJACENCY: return VK_PRIMITIVE_TOPOLOGY_TRIANGLE_LIST_WITH_ADJACENCY;
    case AGPU_TRIANGLE_STRIP: return VK_PRIMITIVE_TOPOLOGY_TRIANGLE_STRIP;
    case AGPU_TRIANGLE_STRIP_ADJACENCY: return VK_PRIMITIVE_TOPOLOGY_TRIANGLE_STRIP_WITH_ADJACENCY;
    case AGPU_PATCHES: return VK_PRIMITIVE_TOPOLOGY_PATCH_LIST;
    }
}

inline enum VkPolygonMode mapPolygonMode(agpu_polygon_mode mode)
{
    switch(mode)
    {
    default:
    case AGPU_POLYGON_MODE_FILL: return VK_POLYGON_MODE_FILL;
    case AGPU_POLYGON_MODE_LINE: return VK_POLYGON_MODE_LINE;
    case AGPU_POLYGON_MODE_POINT: return VK_POLYGON_MODE_POINT;
    }
}

inline enum VkStencilOp mapStencilOperation(agpu_stencil_operation operation)
{
    switch(operation)
    {
    default:
    case AGPU_KEEP: return VK_STENCIL_OP_KEEP;
    case AGPU_ZERO: return VK_STENCIL_OP_ZERO;
    case AGPU_REPLACE: return VK_STENCIL_OP_REPLACE;
    case AGPU_INVERT: return VK_STENCIL_OP_INVERT;
    case AGPU_INCREASE: return VK_STENCIL_OP_INCREMENT_AND_CLAMP;
    case AGPU_INCREASE_WRAP: return VK_STENCIL_OP_INCREMENT_AND_WRAP;
    case AGPU_DECREASE: return VK_STENCIL_OP_DECREMENT_AND_CLAMP;
    case AGPU_DECREASE_WRAP: return VK_STENCIL_OP_DECREMENT_AND_WRAP;
    }
}

inline enum VkCompareOp mapCompareFunction(agpu_compare_function function)
{
    switch (function)
    {
    default:
    case AGPU_ALWAYS: return VK_COMPARE_OP_ALWAYS;
	case AGPU_NEVER: return VK_COMPARE_OP_NEVER;
	case AGPU_LESS: return VK_COMPARE_OP_LESS;
	case AGPU_LESS_EQUAL: return VK_COMPARE_OP_LESS_OR_EQUAL;
	case AGPU_EQUAL: return VK_COMPARE_OP_EQUAL;
	case AGPU_NOT_EQUAL: return VK_COMPARE_OP_NOT_EQUAL;
	case AGPU_GREATER: return VK_COMPARE_OP_GREATER;
	case AGPU_GREATER_EQUAL: return VK_COMPARE_OP_GREATER_OR_EQUAL;
    }
}

inline enum VkBlendFactor mapBlendingFactor(agpu_blending_factor factor, bool color)
{
    switch(factor)
    {
    default:
    case AGPU_BLENDING_ZERO: return VK_BLEND_FACTOR_ZERO;
    case AGPU_BLENDING_ONE: return VK_BLEND_FACTOR_ONE;
    case AGPU_BLENDING_SRC_COLOR: return VK_BLEND_FACTOR_SRC_COLOR;
    case AGPU_BLENDING_INVERTED_SRC_COLOR: return VK_BLEND_FACTOR_ONE_MINUS_SRC_COLOR;
    case AGPU_BLENDING_SRC_ALPHA: return VK_BLEND_FACTOR_SRC_ALPHA;
    case AGPU_BLENDING_INVERTED_SRC_ALPHA: return VK_BLEND_FACTOR_ONE_MINUS_SRC_ALPHA;
    case AGPU_BLENDING_DEST_ALPHA: return VK_BLEND_FACTOR_DST_ALPHA;
    case AGPU_BLENDING_INVERTED_DEST_ALPHA: return VK_BLEND_FACTOR_ONE_MINUS_DST_ALPHA;
    case AGPU_BLENDING_DEST_COLOR: return VK_BLEND_FACTOR_DST_COLOR;
    case AGPU_BLENDING_INVERTED_DEST_COLOR: return VK_BLEND_FACTOR_ONE_MINUS_DST_COLOR;
    case AGPU_BLENDING_SRC_ALPHA_SAT: return VK_BLEND_FACTOR_SRC_ALPHA;
    case AGPU_BLENDING_CONSTANT_FACTOR: return color ? VK_BLEND_FACTOR_CONSTANT_COLOR : VK_BLEND_FACTOR_CONSTANT_ALPHA;
    case AGPU_BLENDING_INVERTED_CONSTANT_FACTOR: return color ? VK_BLEND_FACTOR_ONE_MINUS_CONSTANT_COLOR : VK_BLEND_FACTOR_ONE_MINUS_CONSTANT_ALPHA;
    case AGPU_BLENDING_SRC_1COLOR: return VK_BLEND_FACTOR_SRC1_COLOR;
    case AGPU_BLENDING_INVERTED_SRC_1COLOR: return VK_BLEND_FACTOR_ONE_MINUS_SRC1_COLOR;
    case AGPU_BLENDING_SRC_1ALPHA: return VK_BLEND_FACTOR_SRC1_ALPHA;
    case AGPU_BLENDING_INVERTED_SRC_1ALPHA: return VK_BLEND_FACTOR_ONE_MINUS_SRC1_ALPHA;
    }
}

inline enum VkBlendOp mapBlendingOperation(agpu_blending_operation operation)
{
    switch(operation)
    {
    default:
    case AGPU_BLENDING_OPERATION_ADD: return VK_BLEND_OP_ADD;
    case AGPU_BLENDING_OPERATION_SUBTRACT: return VK_BLEND_OP_SUBTRACT;
    case AGPU_BLENDING_OPERATION_REVERSE_SUBTRACT: return VK_BLEND_OP_REVERSE_SUBTRACT;
    case AGPU_BLENDING_OPERATION_MIN: return VK_BLEND_OP_MIN;
    case AGPU_BLENDING_OPERATION_MAX: return VK_BLEND_OP_MAX;
    }
}

inline enum VkFrontFace mapFaceWinding(agpu_face_winding winding)
{
    switch(winding)
    {
    default:
    case AGPU_COUNTER_CLOCKWISE: return VK_FRONT_FACE_COUNTER_CLOCKWISE;
    case AGPU_CLOCKWISE: return VK_FRONT_FACE_CLOCKWISE;
    }
}

inline enum VkCullModeFlagBits mapCullMode(agpu_cull_mode mode)
{
    switch(mode)
    {
    default:
    case AGPU_CULL_MODE_NONE: return VK_CULL_MODE_NONE;
    case AGPU_CULL_MODE_FRONT: return VK_CULL_MODE_FRONT_BIT;
    case AGPU_CULL_MODE_BACK: return VK_CULL_MODE_BACK_BIT;
    case AGPU_CULL_MODE_FRONT_AND_BACK: return VK_CULL_MODE_FRONT_AND_BACK;
    }
}

inline VkFilter mapMinFilter(agpu_filter filter)
{
    switch (filter)
    {
    default:
    case AGPU_FILTER_MIN_NEAREST_MAG_NEAREST_MIPMAP_NEAREST:return VK_FILTER_NEAREST;
    case AGPU_FILTER_MIN_NEAREST_MAG_NEAREST_MIPMAP_LINEAR: return VK_FILTER_NEAREST;
    case AGPU_FILTER_MIN_NEAREST_MAG_LINEAR_MIPMAP_NEAREST: return VK_FILTER_NEAREST;
    case AGPU_FILTER_MIN_NEAREST_MAG_LINEAR_MIPMAP_LINEAR:  return VK_FILTER_NEAREST;
    case AGPU_FILTER_MIN_LINEAR_MAG_NEAREST_MIPMAP_NEAREST: return VK_FILTER_LINEAR;
    case AGPU_FILTER_MIN_LINEAR_MAG_NEAREST_MIPMAP_LINEAR:  return VK_FILTER_LINEAR;
    case AGPU_FILTER_MIN_LINEAR_MAG_LINEAR_MIPMAP_NEAREST:  return VK_FILTER_LINEAR;
    case AGPU_FILTER_MIN_LINEAR_MAG_LINEAR_MIPMAP_LINEAR:   return VK_FILTER_LINEAR;
    case AGPU_FILTER_ANISOTROPIC:                           return VK_FILTER_LINEAR;
    }
}

inline VkFilter mapMagFilter(agpu_filter filter)
{
    switch (filter)
    {
    default:
    case AGPU_FILTER_MIN_NEAREST_MAG_NEAREST_MIPMAP_NEAREST: return VK_FILTER_NEAREST;
    case AGPU_FILTER_MIN_NEAREST_MAG_NEAREST_MIPMAP_LINEAR:  return VK_FILTER_NEAREST;
    case AGPU_FILTER_MIN_NEAREST_MAG_LINEAR_MIPMAP_NEAREST:  return VK_FILTER_LINEAR;
    case AGPU_FILTER_MIN_NEAREST_MAG_LINEAR_MIPMAP_LINEAR:   return VK_FILTER_LINEAR;
    case AGPU_FILTER_MIN_LINEAR_MAG_NEAREST_MIPMAP_NEAREST:  return VK_FILTER_NEAREST;
    case AGPU_FILTER_MIN_LINEAR_MAG_NEAREST_MIPMAP_LINEAR:   return VK_FILTER_NEAREST;
    case AGPU_FILTER_MIN_LINEAR_MAG_LINEAR_MIPMAP_NEAREST:   return VK_FILTER_LINEAR;
    case AGPU_FILTER_MIN_LINEAR_MAG_LINEAR_MIPMAP_LINEAR:    return VK_FILTER_LINEAR;
    case AGPU_FILTER_ANISOTROPIC:                            return VK_FILTER_LINEAR;
    }
}

inline VkSamplerMipmapMode mapMipmapMode(agpu_filter filter)
{
    switch (filter)
    {
    default:
    case AGPU_FILTER_MIN_NEAREST_MAG_NEAREST_MIPMAP_NEAREST: return VK_SAMPLER_MIPMAP_MODE_NEAREST;
    case AGPU_FILTER_MIN_NEAREST_MAG_NEAREST_MIPMAP_LINEAR:  return VK_SAMPLER_MIPMAP_MODE_LINEAR;
    case AGPU_FILTER_MIN_NEAREST_MAG_LINEAR_MIPMAP_NEAREST:  return VK_SAMPLER_MIPMAP_MODE_NEAREST;
    case AGPU_FILTER_MIN_NEAREST_MAG_LINEAR_MIPMAP_LINEAR:   return VK_SAMPLER_MIPMAP_MODE_LINEAR;
    case AGPU_FILTER_MIN_LINEAR_MAG_NEAREST_MIPMAP_NEAREST:  return VK_SAMPLER_MIPMAP_MODE_NEAREST;
    case AGPU_FILTER_MIN_LINEAR_MAG_NEAREST_MIPMAP_LINEAR:   return VK_SAMPLER_MIPMAP_MODE_LINEAR;
    case AGPU_FILTER_MIN_LINEAR_MAG_LINEAR_MIPMAP_NEAREST:   return VK_SAMPLER_MIPMAP_MODE_NEAREST;
    case AGPU_FILTER_MIN_LINEAR_MAG_LINEAR_MIPMAP_LINEAR:    return VK_SAMPLER_MIPMAP_MODE_LINEAR;
    case AGPU_FILTER_ANISOTROPIC:                            return VK_SAMPLER_MIPMAP_MODE_LINEAR;
    }
}

inline VkSamplerAddressMode mapAddressMode(agpu_texture_address_mode mode)
{
    switch (mode)
    {
    default:
    case AGPU_TEXTURE_ADDRESS_MODE_WRAP:    return VK_SAMPLER_ADDRESS_MODE_REPEAT;
    case AGPU_TEXTURE_ADDRESS_MODE_MIRROR:  return VK_SAMPLER_ADDRESS_MODE_MIRRORED_REPEAT;
    case AGPU_TEXTURE_ADDRESS_MODE_CLAMP:   return VK_SAMPLER_ADDRESS_MODE_CLAMP_TO_EDGE;
    case AGPU_TEXTURE_ADDRESS_MODE_BORDER:  return VK_SAMPLER_ADDRESS_MODE_CLAMP_TO_BORDER;
    case AGPU_TEXTURE_ADDRESS_MODE_MIRROR_ONCE: return VK_SAMPLER_ADDRESS_MODE_MIRROR_CLAMP_TO_EDGE;
    }
}

inline VkImageLayout mapTextureUsageModeToLayout(agpu_texture_usage_mode_mask allAllowedUsages, agpu_texture_usage_mode_mask mode)
{
    switch(int(mode))
    {
    case AGPU_TEXTURE_USAGE_NONE: return VK_IMAGE_LAYOUT_UNDEFINED;
    case AGPU_TEXTURE_USAGE_SAMPLED:
        // TODO: Check on whether this special case makes sense or not.
        if(allAllowedUsages & (AGPU_TEXTURE_USAGE_DEPTH_ATTACHMENT | AGPU_TEXTURE_USAGE_STENCIL_ATTACHMENT))
            return VK_IMAGE_LAYOUT_DEPTH_STENCIL_READ_ONLY_OPTIMAL;
        return VK_IMAGE_LAYOUT_SHADER_READ_ONLY_OPTIMAL;
    case AGPU_TEXTURE_USAGE_COLOR_ATTACHMENT: return VK_IMAGE_LAYOUT_COLOR_ATTACHMENT_OPTIMAL;
    case AGPU_TEXTURE_USAGE_DEPTH_ATTACHMENT:
    case AGPU_TEXTURE_USAGE_STENCIL_ATTACHMENT:
    case AGPU_TEXTURE_USAGE_DEPTH_ATTACHMENT | AGPU_TEXTURE_USAGE_STENCIL_ATTACHMENT:
        return VK_IMAGE_LAYOUT_DEPTH_STENCIL_ATTACHMENT_OPTIMAL;

	case AGPU_TEXTURE_USAGE_COPY_SOURCE: return VK_IMAGE_LAYOUT_TRANSFER_SRC_OPTIMAL;
	case AGPU_TEXTURE_USAGE_COPY_DESTINATION: return VK_IMAGE_LAYOUT_TRANSFER_DST_OPTIMAL;
	case AGPU_TEXTURE_USAGE_PRESENT: return VK_IMAGE_LAYOUT_PRESENT_SRC_KHR;
    case AGPU_TEXTURE_USAGE_STORAGE:
    default: return VK_IMAGE_LAYOUT_GENERAL;
    }
}

inline VkAccessFlags mapBufferUsageModeToAccessFlags(agpu_buffer_usage_mask modes)
{
    VkAccessFlags flags = 0;

    if(modes & AGPU_COPY_DESTINATION_BUFFER)
        flags |= VK_ACCESS_TRANSFER_WRITE_BIT;
    if(modes & AGPU_COPY_SOURCE_BUFFER)
        flags |= VK_ACCESS_TRANSFER_READ_BIT;

    if(modes & AGPU_ARRAY_BUFFER)
        flags |= VK_ACCESS_VERTEX_ATTRIBUTE_READ_BIT;
    if(modes & AGPU_ELEMENT_ARRAY_BUFFER)
        flags |= VK_ACCESS_INDEX_READ_BIT;
    if(modes & (AGPU_UNIFORM_BUFFER | AGPU_STORAGE_BUFFER | AGPU_UNIFORM_TEXEL_BUFFER | AGPU_STORAGE_TEXEL_BUFFER))
        flags |= VK_ACCESS_SHADER_READ_BIT;
    if(modes & (AGPU_DRAW_INDIRECT_BUFFER | AGPU_COMPUTE_DISPATCH_INDIRECT_BUFFER))
        flags |= VK_ACCESS_INDIRECT_COMMAND_READ_BIT;
    if(modes & (AGPU_STORAGE_BUFFER | AGPU_STORAGE_TEXEL_BUFFER))
        flags |= VK_ACCESS_SHADER_WRITE_BIT;

    return flags;
}

inline VkPipelineStageFlags mapBufferUsageModeToSourceStages(agpu_buffer_usage_mask modes)
{
    VkPipelineStageFlags flags = 0;

    if(modes & (AGPU_COPY_DESTINATION_BUFFER | AGPU_COPY_SOURCE_BUFFER))
        flags |= VK_PIPELINE_STAGE_TRANSFER_BIT;

    if(modes & (AGPU_ARRAY_BUFFER | AGPU_ELEMENT_ARRAY_BUFFER))
        flags |= VK_PIPELINE_STAGE_VERTEX_INPUT_BIT;
    if(modes & (AGPU_UNIFORM_BUFFER | AGPU_STORAGE_BUFFER | AGPU_UNIFORM_TEXEL_BUFFER | AGPU_STORAGE_TEXEL_BUFFER))
        flags |= VK_PIPELINE_STAGE_VERTEX_SHADER_BIT | VK_PIPELINE_STAGE_FRAGMENT_SHADER_BIT | VK_PIPELINE_STAGE_COMPUTE_SHADER_BIT;
    if(modes & (AGPU_DRAW_INDIRECT_BUFFER | AGPU_COMPUTE_DISPATCH_INDIRECT_BUFFER))
        flags |= VK_PIPELINE_STAGE_DRAW_INDIRECT_BIT;

    return flags == 0 ? VK_PIPELINE_STAGE_BOTTOM_OF_PIPE_BIT: flags;
}

inline VkPipelineStageFlags mapBufferUsageModeToDestinationStages(agpu_buffer_usage_mask modes)
{
    VkPipelineStageFlags flags = 0;

	if (modes & (AGPU_COPY_DESTINATION_BUFFER | AGPU_COPY_SOURCE_BUFFER))
		flags |= VK_PIPELINE_STAGE_TRANSFER_BIT;

	if (modes & (AGPU_ARRAY_BUFFER | AGPU_ELEMENT_ARRAY_BUFFER))
		flags |= VK_PIPELINE_STAGE_VERTEX_INPUT_BIT;
	if (modes & (AGPU_UNIFORM_BUFFER | AGPU_STORAGE_BUFFER | AGPU_UNIFORM_TEXEL_BUFFER | AGPU_STORAGE_TEXEL_BUFFER))
		flags |= VK_PIPELINE_STAGE_VERTEX_SHADER_BIT | VK_PIPELINE_STAGE_FRAGMENT_SHADER_BIT | VK_PIPELINE_STAGE_COMPUTE_SHADER_BIT;
	if (modes & (AGPU_DRAW_INDIRECT_BUFFER | AGPU_COMPUTE_DISPATCH_INDIRECT_BUFFER))
		flags |= VK_PIPELINE_STAGE_DRAW_INDIRECT_BIT;

    return flags == 0 ? VK_PIPELINE_STAGE_TOP_OF_PIPE_BIT: flags;
}

inline VkAccessFlags mapTextureUsageModeToAccessFlags(agpu_texture_usage_mode_mask allAllowedUsages, agpu_texture_usage_mode_mask mode)
{
    switch(int(mode))
    {
    case AGPU_TEXTURE_USAGE_NONE: return 0;

    case AGPU_TEXTURE_USAGE_COLOR_ATTACHMENT:
        return VK_ACCESS_COLOR_ATTACHMENT_WRITE_BIT;
    case AGPU_TEXTURE_USAGE_DEPTH_ATTACHMENT:
    case AGPU_TEXTURE_USAGE_STENCIL_ATTACHMENT:
    case AGPU_TEXTURE_USAGE_DEPTH_ATTACHMENT | AGPU_TEXTURE_USAGE_STENCIL_ATTACHMENT:
        return VK_ACCESS_DEPTH_STENCIL_ATTACHMENT_WRITE_BIT;

    case AGPU_TEXTURE_USAGE_SAMPLED:
        // TODO: Check on whether this special case makes sense or not.
        if(allAllowedUsages & (AGPU_TEXTURE_USAGE_DEPTH_ATTACHMENT | AGPU_TEXTURE_USAGE_STENCIL_ATTACHMENT))
            return VK_ACCESS_SHADER_READ_BIT | VK_ACCESS_DEPTH_STENCIL_ATTACHMENT_READ_BIT;
        return VK_ACCESS_SHADER_READ_BIT | VK_ACCESS_INPUT_ATTACHMENT_READ_BIT;

    case AGPU_TEXTURE_USAGE_COPY_DESTINATION:
        return VK_ACCESS_TRANSFER_WRITE_BIT;
    case AGPU_TEXTURE_USAGE_COPY_SOURCE:
        return VK_ACCESS_TRANSFER_READ_BIT;

    case AGPU_TEXTURE_USAGE_PRESENT:
        return VK_ACCESS_MEMORY_READ_BIT;

    case AGPU_TEXTURE_USAGE_STORAGE:
    default:
        return VK_ACCESS_SHADER_READ_BIT | VK_ACCESS_INPUT_ATTACHMENT_READ_BIT | VK_ACCESS_SHADER_WRITE_BIT;
    }
}

inline VkPipelineStageFlags mapTextureUsageModeToPipelineSourceStages(agpu_texture_usage_mode_mask allAllowedUsages, agpu_texture_usage_mode_mask mode)
{
    switch(int(mode))
    {
    case AGPU_TEXTURE_USAGE_PRESENT:
    case AGPU_TEXTURE_USAGE_NONE:
        return VK_PIPELINE_STAGE_BOTTOM_OF_PIPE_BIT;
    case AGPU_TEXTURE_USAGE_COLOR_ATTACHMENT:
        return VK_PIPELINE_STAGE_COLOR_ATTACHMENT_OUTPUT_BIT;
    case AGPU_TEXTURE_USAGE_DEPTH_ATTACHMENT:
    case AGPU_TEXTURE_USAGE_STENCIL_ATTACHMENT:
    case AGPU_TEXTURE_USAGE_DEPTH_ATTACHMENT | AGPU_TEXTURE_USAGE_STENCIL_ATTACHMENT:
        return VK_PIPELINE_STAGE_LATE_FRAGMENT_TESTS_BIT;

    case AGPU_TEXTURE_USAGE_SAMPLED:
        // TODO: Check on whether this special case makes sense or not.
        if(allAllowedUsages & (AGPU_TEXTURE_USAGE_DEPTH_ATTACHMENT | AGPU_TEXTURE_USAGE_STENCIL_ATTACHMENT))
            return VK_PIPELINE_STAGE_VERTEX_SHADER_BIT | VK_PIPELINE_STAGE_FRAGMENT_SHADER_BIT | VK_PIPELINE_STAGE_EARLY_FRAGMENT_TESTS_BIT;
        return VK_PIPELINE_STAGE_VERTEX_SHADER_BIT | VK_PIPELINE_STAGE_FRAGMENT_SHADER_BIT;

    case AGPU_TEXTURE_USAGE_COPY_DESTINATION:
    case AGPU_TEXTURE_USAGE_COPY_SOURCE:
        return VK_PIPELINE_STAGE_TRANSFER_BIT;

    case AGPU_TEXTURE_USAGE_STORAGE:
    default:
        return VK_PIPELINE_STAGE_VERTEX_SHADER_BIT | VK_PIPELINE_STAGE_FRAGMENT_SHADER_BIT | VK_PIPELINE_STAGE_COMPUTE_SHADER_BIT;
    }
}

inline VkPipelineStageFlags mapTextureUsageModeToPipelineDestinationStages(agpu_texture_usage_mode_mask allAllowedUsages, agpu_texture_usage_mode_mask mode)
{
    switch(int(mode))
    {
    case AGPU_TEXTURE_USAGE_PRESENT:
    case AGPU_TEXTURE_USAGE_NONE:
        return VK_PIPELINE_STAGE_TOP_OF_PIPE_BIT;
    case AGPU_TEXTURE_USAGE_COLOR_ATTACHMENT:
        return VK_PIPELINE_STAGE_COLOR_ATTACHMENT_OUTPUT_BIT;
    case AGPU_TEXTURE_USAGE_DEPTH_ATTACHMENT:
    case AGPU_TEXTURE_USAGE_STENCIL_ATTACHMENT:
    case AGPU_TEXTURE_USAGE_DEPTH_ATTACHMENT | AGPU_TEXTURE_USAGE_STENCIL_ATTACHMENT:
        return VK_PIPELINE_STAGE_EARLY_FRAGMENT_TESTS_BIT;

    case AGPU_TEXTURE_USAGE_SAMPLED:
        // TODO: Check on whether this special case makes sense or not.
        if(allAllowedUsages & (AGPU_TEXTURE_USAGE_DEPTH_ATTACHMENT | AGPU_TEXTURE_USAGE_STENCIL_ATTACHMENT))
            return VK_PIPELINE_STAGE_VERTEX_SHADER_BIT | VK_PIPELINE_STAGE_FRAGMENT_SHADER_BIT | VK_PIPELINE_STAGE_EARLY_FRAGMENT_TESTS_BIT;
        return VK_PIPELINE_STAGE_VERTEX_SHADER_BIT | VK_PIPELINE_STAGE_FRAGMENT_SHADER_BIT;

    case AGPU_TEXTURE_USAGE_COPY_DESTINATION:
    case AGPU_TEXTURE_USAGE_COPY_SOURCE:
        return VK_PIPELINE_STAGE_TRANSFER_BIT;

    case AGPU_TEXTURE_USAGE_STORAGE:
    default:
        return VK_PIPELINE_STAGE_VERTEX_SHADER_BIT | VK_PIPELINE_STAGE_FRAGMENT_SHADER_BIT | VK_PIPELINE_STAGE_COMPUTE_SHADER_BIT;
    }
}

} // End of namespace AgpuVulkan

#endif // AGPU_VULKAN_CONSTANTS_HPP
